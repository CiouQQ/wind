{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_times 0\n",
      "Current path: [9, 8, 13, 18, 19, 24, 23, 22, 21, 20, 15, 16, 15, 10, 5, 0, 5, 6, 1, 0, 1, 2, 7, 8, 9, 4, 3, 4, 9, 8, 13, 18, 19, 14, 19, 18, 17, 22, 21, 16, 17, 16, 15, 10, 11, 6, 7, 12, 17, 18, 13, 8, 9]\n",
      "Result is  1\n",
      "Episode distance: 530.0\n",
      "Episode length: 24\n",
      "Episode reward: 410.0\n",
      "path [('9', '8'), ('8', '13'), ('13', '18'), ('18', '19'), ('19', '24'), ('24', '23'), ('23', '22'), ('22', '21'), ('21', '20'), ('20', '15'), ('15', '16'), ('16', '15'), ('15', '10'), ('10', '5'), ('5', '0'), ('0', '5'), ('5', '6'), ('6', '1'), ('1', '0'), ('0', '1'), ('1', '2'), ('2', '7'), ('7', '8'), ('8', '9'), ('9', '4'), ('4', '3'), ('3', '4'), ('4', '9'), ('9', '8'), ('8', '13'), ('13', '18'), ('18', '19'), ('19', '14'), ('14', '19'), ('19', '18'), ('18', '17'), ('17', '22'), ('22', '21'), ('21', '16'), ('16', '17'), ('17', '16'), ('16', '15'), ('15', '10'), ('10', '11'), ('11', '6'), ('6', '7'), ('7', '12'), ('12', '17'), ('17', '18'), ('18', '13'), ('13', '8'), ('8', '9')]\n",
      "close\n",
      "Succesful:  100.0 %\n",
      "Average Reward: 410.0\n",
      "Average Length: 24.0\n",
      "Average Distance: 530.0\n",
      "Succesful:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from cpp import generate_gif_from_path\n",
    "from tkinter import filedialog\n",
    "from docopt import docopt\n",
    "from model import ActorCriticModel\n",
    "from utils import create_env\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def init_transformer_memory(trxl_conf, max_episode_steps, device):\n",
    "    \"\"\"Returns initial tensors for the episodic memory of the transformer.\n",
    "\n",
    "    Arguments:\n",
    "        trxl_conf {dict} -- Transformer configuration dictionary\n",
    "        max_episode_steps {int} -- Maximum number of steps per episode\n",
    "        device {torch.device} -- Target device for the tensors\n",
    "\n",
    "    Returns:\n",
    "        memory {torch.Tensor}, memory_mask {torch.Tensor}, memory_indices {torch.Tensor} -- Initial episodic memory, episodic memory mask, and sliding memory window indices\n",
    "    \"\"\"\n",
    "    # Episodic memory mask used in attention\n",
    "    memory_mask = torch.tril(torch.ones((trxl_conf[\"memory_length\"], trxl_conf[\"memory_length\"])), diagonal=-1)\n",
    "    # Episdic memory tensor\n",
    "    memory = torch.zeros((1, max_episode_steps, trxl_conf[\"num_blocks\"], trxl_conf[\"embed_dim\"])).to(device)\n",
    "    # Setup sliding memory window indices\n",
    "    repetitions = torch.repeat_interleave(torch.arange(0, trxl_conf[\"memory_length\"]).unsqueeze(0), trxl_conf[\"memory_length\"] - 1, dim = 0).long()\n",
    "    memory_indices = torch.stack([torch.arange(i, i + trxl_conf[\"memory_length\"]) for i in range(max_episode_steps - trxl_conf[\"memory_length\"] + 1)]).long()\n",
    "    memory_indices = torch.cat((repetitions, memory_indices))\n",
    "    return memory, memory_mask, memory_indices\n",
    "def load_model_path(default = False):\n",
    "    root = tk.Tk()\n",
    "    if default:\n",
    "        return f\"models/20240420-232428/2.391.nn \"\n",
    "    else:\n",
    "        #default folder is model\n",
    "        file_path = filedialog.askopenfilename(initialdir = \"models\")\n",
    "        root.destroy()\n",
    "        return file_path\n",
    "\n",
    "def main(model,times):\n",
    "    # Command line arguments via docopt\n",
    "    _USAGE = \"\"\"\n",
    "    Usage:\n",
    "        enjoy.py [options]\n",
    "        enjoy.py --help\n",
    "    \n",
    "    Options:\n",
    "        --model=<path>              Specifies the path to the trained model [default: ./models/run.nn].\n",
    "    \"\"\"\n",
    "    # options = docopt(_USAGE)\n",
    "    # model_path = options[\"--model\"]\n",
    "    # model_path = load_model_path()   \n",
    "    # Set inference device and default tensor type\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "\n",
    "    # Load model and config\n",
    "    state_dict, config = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "    # Instantiate environment\n",
    "    env = create_env(config[\"environment\"], render=True)\n",
    "\n",
    "    # Initialize model and load its parameters\n",
    "    model = ActorCriticModel(config, env.observation_space, (env.action_space.n,), env.max_episode_steps)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Run and render episode\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    memory, memory_mask, memory_indices = init_transformer_memory(config[\"transformer\"], env.max_episode_steps, device)\n",
    "    memory_length = config[\"transformer\"][\"memory_length\"]\n",
    "    t = 0\n",
    "    obs = env.reset()\n",
    "    # G = env.create_networkx_graph()\n",
    "    # NUM_NODES = env.num_nodes\n",
    "    # Side = int(NUM_NODES**0.5)\n",
    "    # pos = {i: (i % Side, Side - 1 - i // Side) for i in range(NUM_NODES)}\n",
    "    # env.plot_graph(G,  pos, \"test2.png\")\n",
    "    start_time = time.time()\n",
    "    while not done:\n",
    "        # Prepare observation and memory\n",
    "        obs = torch.tensor(np.expand_dims(obs, 0), dtype=torch.float32, device=device)\n",
    "        in_memory = memory[0, memory_indices[t].unsqueeze(0)]\n",
    "        t_ = max(0, min(t, memory_length - 1))\n",
    "        mask = memory_mask[t_].unsqueeze(0)\n",
    "        indices = memory_indices[t].unsqueeze(0)\n",
    "        # Render environment\n",
    "        # env.render()\n",
    "        # Forward model\n",
    "        policy, value, new_memory = model(obs, in_memory, mask, indices) #in_memory ([1, 64, 3, 512]) #indices 64\n",
    "        # print(in_memory[0][0][0])#\n",
    "        memory[:, t] = new_memory\n",
    "        # Sample action\n",
    "        action = []\n",
    "        for action_branch in policy:\n",
    "            action.append(action_branch.probs.argmax().item())\n",
    "        # Step environemnt\n",
    "        # print(\"next step is to go to \",int(action[0]))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_rewards.append(reward)\n",
    "        t += 1\n",
    "    \n",
    "    # after done, render last state\n",
    "    env.render()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Result is \",env.ok)\n",
    "    # print(f\"函數執行耗時：{elapsed_time} 秒\")   \n",
    "    print(\"Episode distance: \" + str(info[\"distance\"]))\n",
    "    print(\"Episode length: \" + str(info[\"length\"]))\n",
    "    print(\"Episode reward: \" + str(info[\"reward\"]))\n",
    "    euler_path = env.path\n",
    "    euler_path = [(str(euler_path[i]), str(euler_path[i + 1])) for i in range(len(euler_path) - 1)]\n",
    "    repeat_path = euler_path\n",
    "    # if env.ok == 0:\n",
    "    generate_gif_from_path(env.create_networkx_graph() , env.get_pos(), euler_path, repeat_path, 1, int(info[\"distance\"]))\n",
    "\n",
    "    \n",
    "    env.close()\n",
    "    return env.ok, info\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = load_model_path() \n",
    "    total_reward = 0\n",
    "    total_length = 0\n",
    "    done_length = 0\n",
    "    total_dinstance = 0\n",
    "    Test_times = 1\n",
    "    done = 0\n",
    "    for i in range(Test_times):\n",
    "        print(\"Test_times\",i)\n",
    "        test, info = main(model_path,i)\n",
    "        done = test + done\n",
    "        total_reward += info[\"reward\"]\n",
    "        total_length += info[\"length\"]\n",
    "        total_dinstance += info[\"distance\"]\n",
    "        if test == 1:\n",
    "            done_length += info[\"length\"]\n",
    "        print(\"Succesful: \", done/(i+1)*100,\"%\")\n",
    "    average_reward = total_reward / Test_times   \n",
    "    average_length = total_length / Test_times  \n",
    "    average_distance = total_dinstance / Test_times\n",
    "    average_succ = done/Test_times\n",
    "    average_succ = done/Test_times\n",
    "    average_done_length = done_length/done\n",
    "\n",
    "    print(\"Average Reward:\", average_reward)\n",
    "    print(\"Average Length:\", average_length)\n",
    "    print(\"Average Distance:\", average_distance)\n",
    "    # print(\"Average Done Length:\", average_done_length)\n",
    "    print(\"Succesful: \", average_succ*100,\"%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppotran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
